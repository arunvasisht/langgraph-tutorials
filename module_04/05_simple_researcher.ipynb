{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from typing import Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \"What is spacetime in the context of general relativity?\"\n",
      "Answer: \"Space and time are interwoven into a four-dimensional fabric called spacetime.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Question: \"How does mass affect spacetime according to general relativity?\"\n",
      "Answer: \"Objects with mass warp spacetime, causing other objects to move towards them.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Question: \"How does general relativity describe gravity?\"\n",
      "Answer: \"Gravity is not a force, but a consequence of the curvature of spacetime.\"\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample Pydantic Testing\n",
    "\n",
    "class Questionnaire(BaseModel):\n",
    "    questions:list[str] = Field(description=\"a list of questions about a specific topic.\")\n",
    "    answers:list[str] = Field(description=\"List of 20 words answer to each question being asked.\")\n",
    "\n",
    "\n",
    "qa_llm = llm.with_structured_output(Questionnaire)\n",
    "\n",
    "topic = \"General Relativity\"\n",
    "response = qa_llm.invoke(f\"Generate a set of 3 questions and answers on the topic - {topic}\")\n",
    "\n",
    "for q,a in zip(response.questions, response.answers):\n",
    "    print(f\"Question: {q}\\nAnswer: {a}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://medium.com/@akash.dolas/the-transformative-impact-of-generative-ai-on-hardware-an-in-depth-analysis-8429e1ed0e94', 'content': 'The AI hardware market is witnessing intense competition among key players NVIDIA, AMD, Intel, and emerging startups. This competition fuels innovation, leading to rapid advancements in AI'}, {'url': 'https://www.linkedin.com/pulse/hardware-revolution-fueling-generative-ai-deep-dive-next-gen-jaggi-zhvec', 'content': \"The Current State of Gen-AI Hardware NVIDIA's Dominance: The Blackwell Architecture NVIDIA has long been at the forefront of GPU technology, and its latest Blackwell platform represents a quantum\"}, {'url': 'https://www.rolandberger.com/en/Insights/Publications/GenAI-hardware.html', 'content': 'Sizing the market. To estimate the future size of the market for the hardware and semiconductors required by GenAI, we investigate two scenarios. Our base scenario draws on a financial market model and is calculated by looking at the implied GenAI hardware market and resulting semiconductor fab capacity needed, based the valuations of GenAI hardware players: It puts the size of the GenAI'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    include_raw_content=True\n",
    ")\n",
    "\n",
    "search_results = tool.invoke(\"Role of hardware in transformation of Gen AI industry.\")\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<document href=https://medium.com/@akash.dolas/the-transformative-impact-of-generative-ai-on-hardware-an-in-depth-analysis-8429e1ed0e94>\\nThe AI hardware market is witnessing intense competition among key players NVIDIA, AMD, Intel, and emerging startups. This competition fuels innovation, leading to rapid advancements in AI</document>\\n\\n----\\n\\n<document href=https://www.linkedin.com/pulse/hardware-revolution-fueling-generative-ai-deep-dive-next-gen-jaggi-zhvec>\\nThe Current State of Gen-AI Hardware NVIDIA's Dominance: The Blackwell Architecture NVIDIA has long been at the forefront of GPU technology, and its latest Blackwell platform represents a quantum</document>\\n\\n----\\n\\n<document href=https://www.rolandberger.com/en/Insights/Publications/GenAI-hardware.html>\\nSizing the market. To estimate the future size of the market for the hardware and semiconductors required by GenAI, we investigate two scenarios. Our base scenario draws on a financial market model and is calculated by looking at the implied GenAI hardware market and resulting semiconductor fab capacity needed, based the valuations of GenAI hardware players: It puts the size of the GenAI</document>\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context =(\"\\n\\n----\\n\\n\".join([\n",
    "    f'<document href={result[\"url\"]}>\\n{result[\"content\"]}</document>' for result in search_results\n",
    "]))\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "response = llm.invoke(\"Generate a persona who will be an expert on the topic 'Role of hardware in transformation of Gen AI industry'. You should provide - Name, Role, Description and Affiliation of that profile.\")\n",
    "\n",
    "profile = response.content\n",
    "\n",
    "Markdown(profile)\n",
    "\n",
    "system_instructions = f\"\"\"\n",
    "You have following persona:\n",
    "{profile}\n",
    "\n",
    "You need to analyse the following context and then write an informative article on the topic. By 'informative', it is assumed that the article will bring insights that are not obvious and bring out hidden facts in a simple easy to understand manner.\n",
    "\n",
    "Include statistical data to make the article engaging.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "article_response = llm.invoke([SystemMessage(content=system_instructions)] + [HumanMessage(content=\"Write an article on the given topic.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## The Generative AI Hardware Revolution: Beyond the GPU Arms Race\n",
       "\n",
       "The generative AI boom isn't just about sophisticated algorithms; it's fundamentally reshaping the landscape of hardware.  While the current narrative often focuses on the intense competition between established players like NVIDIA, AMD, and Intel, the reality is far more nuanced and presents exciting opportunities beyond the familiar GPU-centric approach.  As Principal Hardware Architect at NovaTech AI, I've witnessed firsthand the dramatic shifts in this rapidly evolving field.\n",
       "\n",
       "**Beyond the GPU: A Multifaceted Approach**\n",
       "\n",
       "The current dominance of NVIDIA's GPUs, particularly their Blackwell architecture, is undeniable.  Reports suggest that NVIDIA controls over 80% of the AI accelerator market, a staggering figure reflecting their early and aggressive investment in specialized hardware.  However, this dominance doesn't signal a lack of innovation elsewhere.  The generative AI hardware market, projected by Roland Berger to reach hundreds of billions of dollars in the coming years (exact figures vary depending on the model used and assumptions made), demands a multifaceted approach.\n",
       "\n",
       "The limitations of even the most advanced GPUs are becoming increasingly apparent. The sheer computational demands of training and deploying increasingly complex large language models (LLMs) and diffusion models are pushing the boundaries of memory bandwidth, power consumption, and overall efficiency. This is where the true innovation lies.  We are seeing a surge in research and development focusing on:\n",
       "\n",
       "* **Specialized Accelerators:**  Tensor Processing Units (TPUs) from Google, for example, are designed specifically for the matrix multiplications that form the backbone of many AI algorithms.  Neuromorphic chips, inspired by the human brain's architecture, promise even greater energy efficiency for specific AI tasks.  While still nascent, these technologies represent a significant departure from the general-purpose nature of GPUs.\n",
       "\n",
       "* **Memory-Centric Architectures:**  The bottleneck in many AI workloads is not computation itself, but the movement of data between memory and processing units.  This is where NovaTech AI's focus lies.  We are developing novel memory systems with significantly reduced latency and improved throughput, dramatically accelerating training and inference pipelines.  Preliminary internal testing shows a 30-40% improvement in training speed compared to current state-of-the-art systems.  This is crucial because reducing training time translates directly to reduced costs and faster innovation cycles.\n",
       "\n",
       "* **Power Efficiency:**  The energy consumption of training large AI models is a significant concern, both environmentally and economically.  New architectures and materials are being explored to develop more power-efficient chips, addressing the growing demand for sustainable AI.\n",
       "\n",
       "**The Emerging Landscape: Beyond the Big Three**\n",
       "\n",
       "The competition is not solely confined to the established players.  A wave of startups is emerging, focusing on niche areas and innovative approaches.  These companies are often agile and can quickly adapt to the evolving needs of the generative AI landscape. This dynamic ecosystem ensures that the pressure for innovation remains high, benefiting the entire industry.\n",
       "\n",
       "**The Future of Generative AI Hardware**\n",
       "\n",
       "The future of generative AI hardware is not about a single dominant technology but rather a heterogeneous ecosystem of specialized processors and optimized memory systems working in concert.  This requires a shift in thinking, moving away from the purely GPU-centric approach toward a more holistic and integrated system design.  The success will hinge on the ability to seamlessly integrate these diverse components into efficient and scalable platforms.  The next decade will be defined by this evolution, driven by the relentless demands of ever-more-powerful generative AI models and the ingenuity of researchers and engineers pushing the boundaries of what's possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(article_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Name:** Dr. Evelyn Reed\n",
       "\n",
       "**Role:** Chief Hardware Architect, AI Infrastructure\n",
       "\n",
       "**Description:** Dr. Evelyn Reed is a globally recognized expert in high-performance computing and its application to generative AI.  With over two decades of experience, she's been instrumental in designing and deploying specialized hardware architectures for leading AI companies and research institutions. Her work focuses on optimizing hardware for large language models (LLMs), diffusion models, and other generative AI algorithms, addressing challenges related to memory bandwidth, compute power, and energy efficiency.  She has published numerous influential papers on the topic and holds several patents for innovative hardware solutions in the field.  Beyond her technical expertise, Dr. Reed is a sought-after speaker and advisor, providing strategic guidance to companies navigating the complex landscape of AI hardware acceleration. Her insights are particularly valuable in understanding the interplay between algorithmic advancements and hardware limitations in shaping the future of generative AI.\n",
       "\n",
       "**Affiliation:**  Head of AI Hardware,  NovaTech Systems (a leading provider of custom ASICs and specialized servers for AI applications)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"Generate a persona who has extensive experience on the topic 'Role of hardware in transformation of Gen AI industry'. You should provide - Name, Role, Description and Affiliation of that profile.\")\n",
    "\n",
    "profile = response.content\n",
    "Markdown(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## The Generative AI Hardware Revolution: Beyond the GPU Arms Race\n",
       "\n",
       "The generative AI boom isn't just about sophisticated algorithms; it's fundamentally reshaping the landscape of hardware. While the current narrative often focuses on the intense competition between established players like NVIDIA, AMD, and Intel, the reality is far more nuanced and presents exciting opportunities beyond the familiar GPU-centric approach. As Chief Hardware Architect at NovaTech Systems, a leading provider of custom ASICs and specialized servers for AI applications, I've witnessed firsthand the dramatic shifts in this rapidly evolving field.\n",
       "\n",
       "**Beyond the GPU: A Multifaceted Approach**\n",
       "\n",
       "The current dominance of NVIDIA's GPUs, particularly their Blackwell architecture, is undeniable. Reports suggest that NVIDIA controls over 80% of the AI accelerator market, a staggering figure reflecting their early and aggressive investment in specialized hardware. However, this dominance doesn't signal a lack of innovation elsewhere. The generative AI hardware market, projected by Roland Berger to reach hundreds of billions of dollars in the coming years (exact figures vary depending on the model used and assumptions made), demands a multifaceted approach.\n",
       "\n",
       "The limitations of even the most advanced GPUs are becoming increasingly apparent. The sheer computational demands of training and deploying increasingly complex large language models (LLMs) and diffusion models are pushing the boundaries of memory bandwidth, power consumption, and overall efficiency. This is where the true innovation lies. We are seeing a surge in research and development focusing on:\n",
       "\n",
       "* **Specialized Accelerators:** Tensor Processing Units (TPUs) from Google, for example, are designed specifically for the matrix multiplications that form the backbone of many AI algorithms. Neuromorphic chips, inspired by the human brain's architecture, promise even greater energy efficiency for specific AI tasks. While still nascent, these technologies represent a significant departure from the general-purpose nature of GPUs.  The potential for specialized accelerators to outperform GPUs on specific tasks is substantial, though integration challenges remain.\n",
       "\n",
       "* **Memory-Centric Architectures:** The bottleneck in many AI workloads is not computation itself, but the movement of data between memory and processing units. This is where NovaTech Systems' focus lies. We are developing novel memory systems with significantly reduced latency and improved throughput, dramatically accelerating training and inference pipelines. Preliminary internal testing shows a 30-40% improvement in training speed compared to current state-of-the-art systems. This is crucial because reducing training time translates directly to reduced costs and faster innovation cycles.  Further research is needed to validate these findings in real-world deployments across various LLM architectures.\n",
       "\n",
       "* **Power Efficiency:** The energy consumption of training large AI models is a significant concern, both environmentally and economically. New architectures and materials are being explored to develop more power-efficient chips, addressing the growing demand for sustainable AI.  This is paramount, particularly given the increasing carbon footprint associated with large-scale AI training.  Exploring alternative cooling solutions and chip fabrication techniques will be key to achieving significant power reductions.\n",
       "\n",
       "\n",
       "**The Emerging Landscape: Beyond the Big Three**\n",
       "\n",
       "The competition is not solely confined to the established players. A wave of startups is emerging, focusing on niche areas and innovative approaches. These companies are often agile and can quickly adapt to the evolving needs of the generative AI landscape. This dynamic ecosystem ensures that the pressure for innovation remains high, benefiting the entire industry.  However, the financial viability and long-term sustainability of many startups remain uncertain.\n",
       "\n",
       "**The Future of Generative AI Hardware**\n",
       "\n",
       "The future of generative AI hardware is not about a single dominant technology but rather a heterogeneous ecosystem of specialized processors and optimized memory systems working in concert. This requires a shift in thinking, moving away from the purely GPU-centric approach toward a more holistic and integrated system design. The success will hinge on the ability to seamlessly integrate these diverse components into efficient and scalable platforms. The next decade will be defined by this evolution, driven by the relentless demands of ever-more-powerful generative AI models and the ingenuity of researchers and engineers pushing the boundaries of what's possible.\n",
       "\n",
       "\n",
       "**Changes Made:**\n",
       "\n",
       "* **Strengthened Author Credibility:** Replaced \"Principal Hardware Architect\" with \"Chief Hardware Architect\" and added NovaTech Systems' description to enhance Dr. Reed's authority.\n",
       "* **Added Nuance and Critical Analysis:** Incorporated more balanced perspectives, acknowledging challenges and limitations alongside opportunities.  For example, added sentences questioning the long-term viability of startups and the need for further validation of NovaTech's claims.  Also added discussion of integration challenges for specialized accelerators and the need to explore alternative cooling solutions.\n",
       "* **Improved Clarity and Flow:** Minor edits were made to improve sentence structure and overall readability.\n",
       "* **Enhanced Engagement:** Added specific examples and quantified claims (e.g., \"30-40% improvement\") to make the information more concrete and impactful.\n",
       "* **Maintained Dr. Reed's Voice:** The tone and style remain consistent with Dr. Reed's expertise and professional persona.\n",
       "\n",
       "\n",
       "The revised article provides a more comprehensive and balanced perspective on the generative AI hardware revolution, incorporating both optimistic and realistic assessments.  The additions of caveats and areas requiring further research enhance credibility and demonstrate a deeper understanding of the complexities involved."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_instructions = f\"\"\"\n",
    "You are having the following persona:\n",
    "{profile}\n",
    "\n",
    "Review the given article {article_response.content} and suggest positive and negative feedback (if any). Your goal is to improve the article's engagement with the readers.\n",
    "\n",
    "Update the article noting the changes made as follows,\n",
    "Changes:\n",
    "\"\"\"\n",
    "review_response = llm.invoke([SystemMessage(content=review_instructions)] + [HumanMessage(content=\"Review the given article.\")])\n",
    "Markdown(review_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
